{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    response=ollama.generate(model='llama2',prompt=prompt)\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "API (Application Programming Interface) and REST (Representational State Transfer) are both architectural styles used to build web services. While they share some similarities, there are also some key differences:\n",
      "\n",
      "1. Definition:\n",
      "\t* API: A set of rules and protocols that defines how software components should interact with each other. It specifies the syntax, data formats, and communication protocols used in the interaction.\n",
      "\t* REST: A architectural style that uses HTTP to build web services. It relies on a resource-based architecture, where resources are identified by URIs, and can be manipulated using a fixed set of operations (GET, POST, PUT, DELETE).\n",
      "2. Request/Response Model:\n",
      "\t* API: Can use any request/response model, but typically uses a synchronous model where the client sends a request to the server and waits for the response.\n",
      "\t* REST: Uses a stateless model, where each request contains all the information necessary to complete the request, and the server does not retain any information about the previous requests.\n",
      "3. Verbs:\n",
      "\t* API: Can use any verb (e.g., GET, POST, PUT, DELETE) to perform operations on resources.\n",
      "\t* REST: Uses a fixed set of verbs (GET, POST, PUT, DELETE) to manipulate resources.\n",
      "4. Resources:\n",
      "\t* API: Can represent any type of data or resource, including complex objects and nested structures.\n",
      "\t* REST: Uses URIs to identify resources, which can be simple or complex objects.\n",
      "5. Statelessness:\n",
      "\t* API: Can be stateless or stateful, depending on the design.\n",
      "\t* REST: Must be stateless, as each request contains all the information necessary to complete the request.\n",
      "6. Cacheability:\n",
      "\t* API: Can cache responses to improve performance, but it depends on the design.\n",
      "\t* REST: Responses are typically cacheable, as they contain enough information for the client to make subsequent requests without requiring a full response from the server.\n",
      "7. Language Agnosticism:\n",
      "\t* API: Can be language-specific or language-agnostic.\n",
      "\t* REST: Must be language-agnostic, as it relies on HTTP and other standard protocols that are independent of programming languages.\n",
      "8. Complexity:\n",
      "\t* API: Can have a more complex architecture, with multiple layers and modules.\n",
      "\t* REST: Has a simpler architecture, with a clear separation between resources and operations.\n",
      "9. Performance:\n",
      "\t* API: Can have better performance due to caching and other optimization techniques.\n",
      "\t* REST: Typically has lower overhead compared to APIs, as it relies on standard protocols and does not require additional infrastructure.\n",
      "10. Security:\n",
      "\t* API: Can have more advanced security measures, such as authentication and authorization.\n",
      "\t* REST: Requires proper security measures, such as SSL/TLS encryption, to protect resources and prevent unauthorized access.\n",
      "\n",
      "In summary, while both API and REST are used for building web services, they differ in their request/response model, resource representation, statelessness, cacheability, language agnosticism, complexity, performance, and security features. REST is generally simpler, more lightweight, and easier to implement than APIs, but may not offer the same level of flexibility and customization.\n"
     ]
    }
   ],
   "source": [
    "response=generate_text(prompt=\"Difference between API and REST API\")\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    response=ollama.generate(model='llama2',prompt=prompt)\n",
    "    return response\n",
    "def answer_question(question):\n",
    "    prompt=f'please give the answer for the following question in a single sentence:\\n\\n{question}'\n",
    "    return generate_text(prompt)\n",
    "def summarize_text(text):\n",
    "    prompt=f'please give a summary in 2-3 sentence:\\n\\n {text}'\n",
    "    return generate_text(prompt)\n",
    "def translate(text):\n",
    "    prompt=f'please translate the text in to german:\\n\\n{text}'\n",
    "    return generate_text(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama llama2 Text Processing Tool:\n",
      "\n",
      "\n",
      "The choices are: \n",
      "\n",
      "\n",
      "1.Generate Text\n",
      "2.Question Answering\n",
      "3.Summarizing\n",
      "4.Translation\n",
      "\n",
      "Fine-tuning is a process in machine learning and artificial intelligence where a pre-trained model is adjusted or adapted for a specific task or dataset. The goal of fine-tuning is to improve the performance of the model on the new task or dataset, without requiring a complete overhaul of the original model.\n",
      "\n",
      "Fine-tuning involves updating the weights of the model using a small amount of training data from the target task or dataset. This process allows the model to learn the specific patterns and features present in the new data, while still leveraging the knowledge and capabilities it gained from the original training data.\n",
      "\n",
      "Fine-tuning is useful when:\n",
      "\n",
      "1. The model has already been trained on a large dataset, but the target task or dataset is different from the original training data.\n",
      "2. The model needs to be adapted for a specific application or use case.\n",
      "3. The model has not performed well on the new task or dataset, and fine-tuning can help improve its performance.\n",
      "4. The model needs to be updated to incorporate new features or modalities.\n",
      "\n",
      "Fine-tuning can be applied to various machine learning models, including:\n",
      "\n",
      "1. Neural networks: Fine-tuning a pre-trained neural network for a specific task or dataset involves adjusting the weights of the network using a small amount of training data from the target task or dataset.\n",
      "2. Language models: Fine-tuning a pre-trained language model for a specific task or dataset involves adjusting the weights of the model to learn the specific patterns and features present in the new data.\n",
      "3. Transfer learning: Fine-tuning a pre-trained model on a new task or dataset is an example of transfer learning, where the knowledge gained from the original training data is applied to the new task or dataset.\n",
      "\n",
      "The benefits of fine-tuning include:\n",
      "\n",
      "1. Improved performance: Fine-tuning can lead to improved performance on the target task or dataset compared to using a model that has not been adapted for the specific task.\n",
      "2. Reduced training time: Fine-tuning a pre-trained model can reduce the amount of training data required to achieve good performance, as the model has already learned general features and patterns from the original training data.\n",
      "3. Sharing knowledge across tasks: Fine-tuning allows the model to share knowledge across tasks, which can lead to better performance on related tasks in the future.\n",
      "\n",
      "In summary, fine-tuning is a powerful technique in machine learning that allows models to be adapted and improved for specific tasks or datasets without requiring significant changes to the original model architecture.\n"
     ]
    }
   ],
   "source": [
    "print('''Ollama llama2 Text Processing Tool:\\n\\n\n",
    "The choices are: \\n\\n\n",
    "1.Generate Text\n",
    "2.Question Answering\n",
    "3.Summarizing\n",
    "4.Translation''')\n",
    "choice=input(\"enter the choice_value:\\n\\n\")\n",
    "if choice=='1':\n",
    "    prompt=input(\"Enter your prompt\")\n",
    "    result=generate_text(prompt)\n",
    "if choice=='2':\n",
    "    question=input(\"Enter your question\")\n",
    "    result=answer_question(question)\n",
    "if choice=='3':\n",
    "    text=input(\"Enter your Summarizing text\")\n",
    "    result=summarize_text(text)\n",
    "if choice=='4':\n",
    "    text=input(\"Enter your Translation text\")\n",
    "    result=translate(text)\n",
    "response=result['response']\n",
    "print(f'Response: {response}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama llama2 Text Processing Tool:\n",
      "\n",
      "\n",
      "The choices are: \n",
      "\n",
      "\n",
      "1.Generate Text\n",
      "2.Question Answering\n",
      "3.Summarizing\n",
      "4.Translation\n",
      "Self-attention is a mechanism in deep learning models that allows them to focus on specific parts of the input data, rather than treating the entire input as a whole, by computing a weighted sum of the input based on the similarity between each element and a query vector.\n"
     ]
    }
   ],
   "source": [
    "print('''Ollama llama2 Text Processing Tool:\\n\\n\n",
    "The choices are: \\n\\n\n",
    "1.Generate Text\n",
    "2.Question Answering\n",
    "3.Summarizing\n",
    "4.Translation''')\n",
    "choice=input(\"enter the choice_value:\\n\\n\")\n",
    "if choice=='1':\n",
    "    prompt=input(\"Enter your prompt\")\n",
    "    result=generate_text(prompt)\n",
    "if choice=='2':\n",
    "    question=input(\"Enter your question\")\n",
    "    result=answer_question(question)\n",
    "if choice=='3':\n",
    "    text=input(\"Enter your Summarizing text\")\n",
    "    result=summarize_text(text)\n",
    "if choice=='4':\n",
    "    text=input(\"Enter your Translation text\")\n",
    "    result=translate(text)\n",
    "response=result['response']\n",
    "print(f'Response for your Question:{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama llama2 Text Processing Tool:\n",
      "\n",
      "\n",
      "The choices are: \n",
      "\n",
      "\n",
      "1.Generate Text\n",
      "2.Question Answering\n",
      "3.Summarizing\n",
      "4.Translation\n",
      "\n",
      "Sure! Here's a summary of the information you provided in 3 sentences:\n",
      "\n",
      "The Hugging Face Hub hosts various machine learning models that can be downloaded remotely using the Hugging Face Transformers library. These models can also be accessed indirectly through APIs, allowing for direct use without the need to download them first. By leveraging these remote access options, developers and researchers can easily incorporate pre-trained models into their applications or experiments without having to manage the underlying infrastructure.\n"
     ]
    }
   ],
   "source": [
    "print('''Ollama llama2 Text Processing Tool:\\n\\n\n",
    "The choices are: \\n\\n\n",
    "1.Generate Text\n",
    "2.Question Answering\n",
    "3.Summarizing\n",
    "4.Translation''')\n",
    "choice=input(\"enter the choice_value:\\n\\n\")\n",
    "if choice=='1':\n",
    "    prompt=input(\"Enter your prompt\")\n",
    "    result=generate_text(prompt)\n",
    "if choice=='2':\n",
    "    question=input(\"Enter your question\")\n",
    "    result=answer_question(question)\n",
    "if choice=='3':\n",
    "    text=input(\"Enter your Summarizing text\")\n",
    "    result=summarize_text(text)\n",
    "if choice=='4':\n",
    "    text=input(\"Enter your Translation text\")\n",
    "    result=translate(text)\n",
    "response=result['response']\n",
    "print(f'Summary output:{ response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama llama2 Text Processing Tool:\n",
      "\n",
      "\n",
      "The choices are: \n",
      "\n",
      "\n",
      "1.Generate Text\n",
      "2.Question Answering\n",
      "3.Summarizing\n",
      "4.Translation\n",
      "Translation output:Guten Morgen\n"
     ]
    }
   ],
   "source": [
    "print('''Ollama llama2 Text Processing Tool:\\n\\n\n",
    "The choices are: \\n\\n\n",
    "1.Generate Text\n",
    "2.Question Answering\n",
    "3.Summarizing\n",
    "4.Translation''')\n",
    "choice=input(\"enter the choice_value:\\n\\n\")\n",
    "if choice=='1':\n",
    "    prompt=input(\"Enter your prompt\")\n",
    "    result=generate_text(prompt)\n",
    "if choice=='2':\n",
    "    question=input(\"Enter your question\")\n",
    "    result=answer_question(question)\n",
    "if choice=='3':\n",
    "    text=input(\"Enter your Summarizing text\")\n",
    "    result=summarize_text(text)\n",
    "if choice=='4':\n",
    "    text=input(\"Enter your Translation text\")\n",
    "    result=translate(text)\n",
    "response=result['response']\n",
    "print(f'Translation output:{response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
